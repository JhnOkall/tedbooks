/**
 * @file This file defines the API route for generating secure upload URLs for Vercel Blob.
 * It follows the recommended client-side upload pattern to bypass serverless function body size limits.
 * This is a protected, admin-only endpoint.
 */

import { handleUpload, type HandleUploadBody } from '@vercel/blob/client';
import { NextResponse } from 'next/server';
import { auth } from '@/auth';

// This is the new, recommended way to handle uploads.
// The client will send a request to this endpoint, and we'll return
// a short-lived token that allows the client to upload directly to Vercel Blob.
export async function POST(request: Request): Promise<NextResponse> {
  // Step 1: Authenticate the user and check for admin role.
  const session = await auth();
  if (!session || session.user?.role !== 'admin') {
    return NextResponse.json(
      { message: 'Forbidden: Admins only' },
      { status: 403 }
    );
  }

  // Step 2: Parse the request body.
  // The `handleUpload` function from `@vercel/blob/client` expects a specific JSON structure.
  const body = (await request.json()) as HandleUploadBody;

  try {
    // Step 3: Use `handleUpload` to generate the secure upload token.
    // It takes care of all the Vercel Blob API interactions.
    const jsonResponse = await handleUpload({
      body,
      request,
      // The `onBeforeGenerateToken` callback is crucial for security.
      // It's where we define the path for the upload and any security checks.
      onBeforeGenerateToken: async (
        pathname: string,
        /* clientPayload?: string, */
      ) => {
        // Here, you can add any metadata or logic you need.
        // For example, we can prefix the pathname to organize files.
        // The `pathname` will be the original filename from the client.

        // IMPORTANT: We're not using the full API from your original example
        // (like slugify or nanoid) here because the client-side `upload` function
        // automatically adds a unique suffix to prevent overwrites, which is generally safer.
        // Let's organize files into 'covers/' and 'books/' folders.
        const { searchParams } = new URL(request.url);
        const uploadType = searchParams.get('uploadType');

        let finalPathname = pathname;
        if (uploadType === 'cover') {
            finalPathname = `images/covers/${pathname}`;
        } else if (uploadType === 'book') {
            finalPathname = `books/${pathname}`;
        }

        return {
          allowedContentTypes:
            uploadType === 'cover'
              ? ['image/jpeg', 'image/png', 'image/webp', 'image/gif']
              : ['application/pdf', 'application/epub+zip'],
          pathname: finalPathname,
          // You can add more security checks here if needed, e.g., based on clientPayload.
        };
      },
      // The `onUploadCompleted` callback can be used for post-processing,
      // like updating a database, but we'll handle that on the client side for this use case.
      onUploadCompleted: async ({ blob, tokenPayload }) => {
        // console.log('blob upload completed', blob, tokenPayload);
        // You can perform database operations here if you want.
      },
    });

    // Step 4: Return the JSON response generated by `handleUpload`.
    // This response contains the upload URL and token for the client.
    return NextResponse.json(jsonResponse);

  } catch (error) {
    console.error('Error handling upload token generation:', error);
    return NextResponse.json(
      { message: 'An internal error occurred.' },
      { status: 500 }
    );
  }
}